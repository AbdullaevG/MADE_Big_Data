## HW #08: Real Time

В данном ДЗ нужно решить 2 задачи. Решение надо выполнить с помощью Spark Structured Streaming.

**WARNING**:   маловероятно, но при условии перезагрузки (или прочих проблем) на
сервере типа client, поток данных в Kafka может быть прерван. Для возобновления
потока данных обратитесь в чатике курса к преподавателям и/или поддержке курса.
При отсутствии стрима свежих данных попробуйте установить отступы на чтение
данных из Kafka вручную (подробнее - Structured Streaming Kafka Integration).

1. **Задача #1 (Task ID: realtime.domain_stat): статистика посещения доменов**
   В этом домашнем задании вам предстоит определить наиболее популярные домены по посещаемости и подсчитать число уников (то есть уникальных пользователей),
которые зашли на этот домен.
-----------------------------------------------------------------------------------------------------------------------------------------------------
В этом и последующем заданиях для парсинга домена используйте функцию из
spark.sql:

    select parse_url(`url_col`, 'HOST') as domain;
------------------------------------------------------------------------------------------------------------------------------------------------------

- Входные данные - поток событий просмотра страниц в Kafka
- Брокеры кафка: `brain-node1.bigdatateam.org:9092,brain-node2.bigdatateam.org:9092,brain-node3.bigdatateam.org:9092`
- Топик кафка: `page_views`
- Формат строчки: tsv
- В каждой строке находятся следующие поля, разделенные знаком табуляции:
  - DOUBLE - TS (unixtime) события;
  - STRING - UID пользователя;
  - STRING - URL;
  - STRING - Title страницы;
  - STRING - User-Agent пользователя;
- Решение должно быть реализовано на `Spark Structured Streaming`
- Ваше решение должно печатать в STDOUT топ-10 самых популярных (по просмотрам) доменов с информацией об общем числе просмотров этого домена и числа уников, которые на него зашли.
- Результат - это кумулятивная статистика за всё время работы Streaming, отсортированная по убыванию числа просмотров
- Результат должен выводиться в консоль каждые 5 секунд
  - Если ваш код не успевает уложиться в этот интервал - возможно, проблема в избыточном числе партиций
  - Важно выводить таблицу целиком и не обрезать длину столбцов (опция truncate должна быть выключена)
- скрипты выводят на экран (STDOUT) указанное в задании число строк в нужном формате каждый батч. Если вы запускаете spark streaming с триггером по
  времени или по умолчанию, то первый батч будет пустым и это нормально. Запуск решения при проверке будет запускаться с тригером once и если вы все
  написали правильно - то первый батч пустым не будет;


2. **Задача #2 (Task ID: realtime.runet_stat): оконная статистика посещения рунета**

   В этом домашнем задании вам предстоит определить видимый трафик в зоне ru и в
остальном интернете. Сравнение производится на окне размером в 2 секунды каждую
секунду (нас в обоих случаях интересует время события (поле TS из лога), а не
обработки). Для трафика требуется подсчитать характеристики: число просмотров и
число уников.

 - Решение должно быть реализовано на `Spark Structured Streaming`;
 - Ваше решение должно печатать в STDOUT агрегированную статистику для сайтов зоны RU и остальных;
 - Статистика - это число просмотров и число уников, которые в определенный интервал зашли на искомую группу доменов;
 - Статистика рассчитывается за две секунды лога каждую секунду (под временем здесь подразумевается именно время события);
 - Результат - это кумулятивная статистика за всё время работы Streaming, отсортированная по времени окна и убыванию числа просмотров в каждом окне;
 - Решение должно выводить в консоль только первые 20 результатов работы;
 - Результат выводится в консоль по мере готовности
 - Важно выводить таблицу целиком и не обрезать длину столбцов (опция truncate должна быть выключена)



