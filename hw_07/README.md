## HW #07: Spark Advanced


Помимо привычных и тривиальных случаев, когда датафрейм имеет вид:

Набор колонок (столбцов) → данные

Бывают случаи, когда данные имеют вложенную структуру. Примеры:
 - для товаров в интернет-магазине можно выделить категорию “еда” и
подкатегорию (вложенную структуру) “рыба”. Можно пойти ещё дальше и
указать вид приготовления (свежая/ солёная/ копчёная). Тогда структура
такого датафрейма будем иметь вид:

    товары → категория(еда) → подкатегория (рыба) → вид приготовления
    → данные
 - автомобили, где вложенной структурой можно указать их тип - легковой/
грузовой, уточнить бренд, указать модель авто и учесть, что модель бывает с
разными коробками передач:

    автомобили → тип → бренд → модель → тип коробки передач → данные

В данном ДЗ с помощью Spark нужно решить 1 задачу по трансформации данных с
вложенной структурой.

Решать будем наиболее часто встречающуюся проблему с Dataframes API -
CRUD (сокр. от Create, Read, Update, Delete), действия над колонками вашего
dataframe. Любая колонка в Spark - это инстанс pyspark.sql.Column.

Чтобы добавить новую (или изменить существующую колонку есть два основных
варианта:
 - использовать `df.withColumn(name, value)`, где `name` - это имя новой или
существующей колонки, а `value` - новое значение колонки, которое имеет тип
`pyspark.sql.Column` (например, `lit(1)` - константа 1, `col("b")` значение из
колонки b, `rand()` - случайное значение. Все эти функции представлены в
пакете `pyspark.sql.functions`;
 - использовать `df.select(col1, col2, col3)` - где `col1`, `col2`, `col3` - это
список колонок, которые нужно "заселектить" в dataframe. При этом это могут
быть как новые, так и существующие колонки, имеющие тип
`pyspark.sql.Column`.

Если колонка является структурой (то есть, имеет тип struct в printSchema), то
подполя этой колонки можно выбрать, используя "." в col(). Например, вот так:
col("car.brand"). К сожалению, в Spark нет встроенной функции, чтобы изменить
значение поля brand в колонке col("car"). Если вы попытаетесь использовать
функцию df.withColumn("car.brand", new_value), то вместо ожидаемого результата
вы получите новую колонку с именем "car.brand", которая не будет входить в состав
колонки "car"

В рамках данного домашнего задания вам необходимо разработать функцию, которая
изменяет любое поле dataframe, включая вложенные поля внутри структур любого
уровня вложенности. Ниже представлен скелет этой функции.

```
    def update_df(df, columns_dict):
      """
      Updates existing columns or creates new in dataframe df using
      columns from columns_dict.
      :param df: input dataframe
      :type df: pyspark.sql.Dataframe
      :param columns_dict: Key-value dictionary of columns which need to
      be updated. Key is a column name in
      the format of path.to.col
      :type param: Dict[str, pyspark.sql.Column]
      :return: dataframe with updated columns
      :rtype pyspark.sql.DataFrame
      """
      updated_df = df
      # TODO
      return updated_df
```
